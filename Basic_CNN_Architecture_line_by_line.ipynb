{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "5-1강 CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbWSckjqEtBO"
      },
      "source": [
        "# 5. CNN을 이용한 분류 (CIFAR10)\n",
        "\n",
        "합성곱 신경망(Convolutional Neural Network)를 이용한 이미지 분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBv43acUEtBY"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv22bgoxEtBZ"
      },
      "source": [
        "## 5.1 CIFAR10 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItHOAe6TH1fI",
        "outputId": "26ee6707-785f-4ebf-e513-0b1a585ca20a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zed0IHm-H3xa",
        "outputId": "835a2043-e0c0-4280-ce4c-0f101e940cfc"
      },
      "source": [
        "cd/content/drive/MyDrive/Colab_Notebooks/deeplearningbro/pytorch"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab_Notebooks/deeplearningbro/pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR7AWTpkEtBa",
        "outputId": "b970c5c7-edee-4ce8-fa8f-0b3e2fcc069e"
      },
      "source": [
        "# CIFAR10: 클래스 10개를 가진 이미지 데이터\n",
        "# 'plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # 0,1,2 각각의 채널에 mean과 std를 곱해서 정규화\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True) # 데이터를 배치 형태로 만들기\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZTDIdOkGrQi",
        "outputId": "38fbcbbd-f162-4d56-c114-d1348a58b28e"
      },
      "source": [
        "# CPU or GPU :: 연산 종류 확인\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'{device} is available.')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0 is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfT1ARZCEtBb"
      },
      "source": [
        "## 5.2 CNN 모델 구축"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7tpEt6NEtBb"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5) # 합성곱 연산 (입력 채널수 3, 출력 채널수 6, 필터크기 5x5 , stride=1(defualt))\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # 합성곱 연산 (필터크기 2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5) # 합성곱 연산 (입력 채널수 6, 출력 채널수 16, 필터크기 5x5 , stride=1(defualt))\n",
        "        self.pool2 = nn.MaxPool2d(2, 2) # 합성곱 연산 (필터크기 2, stride=2)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 5x5 피쳐맵 16개를 일렬로 피면 16*5*5개의 노드가 생성\n",
        "        self.fc2 = nn.Linear(120, 10) # 120개 노드에서 클래스의 개수인 10개의 노드로 연산\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv1(x))) # conv1 -> ReLU -> pool1\n",
        "        x = self.pool2(F.relu(self.conv2(x))) # conv2 -> ReLU -> pool2\n",
        "        x = x.view(-1, 16 * 5 * 5) # 5x5 피쳐맵 16개를 일렬로 만든다. // 여기서 -1은 배치 수 .\n",
        "        # CrossEntropyLoss는 softmax 계산까지 포함되어 있으므로 모델의 마지막 output node에 별도의 활성화 함수를 사용하지 않아도 된다.\n",
        "        x = F.relu(self.fc1(x)) \n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "net = Net().to(device) # 모델 선언\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoXGMaN9EtBc",
        "outputId": "036c7781-5eba-4f66-8940-352fcaa96042"
      },
      "source": [
        "print(net)\n",
        "# 피쳐의 크기: 32 -> 28 ->14 -> 10 -> 5\n",
        "\n",
        "'''\n",
        "16 * 5 * 5 ::\n",
        "너비 높이가 같은 입력 이미지를 사용할 경우 피쳐맵의 가로 세로 크기는 일반적으로 다음과 같이 계산 됩니다. \n",
        "\n",
        "output size = 1 + (input size + 2*padding - filter size)/stride\n",
        "\n",
        "따라서 각 층을 위 식과 필터 개수를 같이 고려하여 계산하면 다음과 같은 결과를 얻게 됩니다.\n",
        "\n",
        "입력 이미지 크기 3x32x32\n",
        "\n",
        "conv1의 피쳐맵 크기 1+(32-5)/1=28 -> 6x28x28\n",
        "\n",
        "pool1의 피쳐맵 크기 1+(28-2)/2=14 -> 6x14x14\n",
        "\n",
        "conv2의 피쳐맵 크기 1+(14-5)/1=10 -> 16x10x10\n",
        "\n",
        "pool2의 피쳐맵 크기 1+(10-2)/2=5 -> 16x5x5\n",
        "\n",
        "'''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ogPhPJ2EtBd"
      },
      "source": [
        "## 5.3 모델 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXE_rdNVEtBd"
      },
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss() # CrossEntropyLoss는 softmax 계산까지 포함되어 있으므로 모델의 마지막 output node에 별도의 활성화 함수를 사용하지 않아도 된다.\n",
        "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4YVuZXyEtBd",
        "outputId": "b6377766-09b9-4f1a-91ca-2b6050a63ade"
      },
      "source": [
        "# 모델의 학습 과정인 4강에서 배운 인공 신경망과 동일하다.\n",
        "loss_ = [] # 그래프를 그리기 위한 loss 저장용 리스트 \n",
        "n = len(trainloader) # 배치 개수\n",
        "\n",
        "for epoch in range(10):  # 10번 학습을 진행한다.\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "        inputs, labels = data[0].to(device), data[1].to(device) # 배치 데이터 GPU용 :: GPU 계산이 가능한 Tensor로 만들어줌.\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs) # 예측값 산출 :: 이미지 받아서 10개짜리 노드 산출\n",
        "        loss = criterion(outputs, labels) # 손실함수(Cross Entropy) 계산 :: 여기서  label은 0~9 로 숫자 하나 값 / outputs : node가 10개인 vector\n",
        "        '''\n",
        "        파이토치에서 크로스 엔트로피에 해당하는 criterion(A, B)에서  A의 크기를 (배치 크기)x(클래스 수), B의 크기를 (배치 크기)로 입력 받도록 정의하였습니다. \n",
        "        즉, 입력 형식을 맞춰 주셔야만 사용이 가능하다는 말입니다. 생각하고 계신 계산 과정은 내부에서 자동으로 처리해 주는 것이므로 걱정 안 하셔도 되요 :)\n",
        "        '''\n",
        "        loss.backward() # 손실함수 기준으로 역전파 선언\n",
        "        optimizer.step() # 가중치 최적화\n",
        "\n",
        "        # print statistics\n",
        "        # 배치마다 계산이 되는 거기 때문에 배치마다의 loss를 더해서\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    loss_.append(running_loss / n)  # 평균 loss로 epoch 1개당의 loss\n",
        "    print('[%d] loss: %.3f' %(epoch + 1, running_loss / len(trainloader)))\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] loss: 1.749\n",
            "[2] loss: 1.335\n",
            "[3] loss: 1.183\n",
            "[4] loss: 1.085\n",
            "[5] loss: 1.014\n",
            "[6] loss: 0.958\n",
            "[7] loss: 0.909\n",
            "[8] loss: 0.869\n",
            "[9] loss: 0.833\n",
            "[10] loss: 0.798\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3Qlr8XzJ-dG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "31d610cc-de87-4730-e38d-def39d7eba34"
      },
      "source": [
        "plt.plot(loss_)\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiAQL6l2EtBe"
      },
      "source": [
        "## 5.4 모델 저장하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjFHckKoEtBe"
      },
      "source": [
        "PATH = './models/cifar_net.pth' # 모델 저장 경로 \n",
        "torch.save(net.state_dict(), PATH) # 모델(의 파라미터) 저장"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V72jwNfEtBf"
      },
      "source": [
        "## 5.5 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrs94OgCEtBf",
        "outputId": "c2e4d0e7-30d7-43d6-fc51-c6ce7ffe8a97"
      },
      "source": [
        "# 위에서 GPU 용으로 모델 파라미터를 계산했으므로 모델 파라미터를 받을 모델의 뼈대도 GPU용으로 만들고 GPU로 계산해야 함.\n",
        "# 모델 불러오기는 엄밀히 말하자면 \"모델의 파라메타\"를 불러오는 것이다. <<따라서 모델의 뼈대를 먼저 선언>>하고\n",
        "# 모델의 파라메타를 불러와 pretrained model을 만든다.\n",
        "\n",
        "net = Net().to(device) # 모델 선언\n",
        "net.load_state_dict(torch.load(PATH)) # 모델 파라메타 불러오기"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H6TXyfnEtBg"
      },
      "source": [
        "## 5.6 모델 정확도(Accuracy) 구하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmMKCIhMEtBg",
        "outputId": "2977b050-47b1-47f5-c3ac-05e3e2f277f6"
      },
      "source": [
        "# 모델 정확도는 Update가 되지 않기 때문에 with torch.no_grad() 구문 안에\n",
        "# 평가 데이터를 이용해 정확도를 구해보자.\n",
        "# output은 미니배치의 결과가 산출되기 때문에 for문을 통해서 test 전체의 예측값을 구한다.\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    \n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0) # 개수 누적(총 개수)\n",
        "        correct += (predicted == labels).sum().item() # 누적(맞으면 1, 틀리면 0으로 합산)\n",
        "        \n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 64 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# _, predicted = torch.max(outputs.data, 1)의 의미\n",
        "'''\n",
        "outputs의 크기가 (배치 크기)x(클래스의 개수)이므로  열이 하나의 이미지의 대응되는 벡터를 나타냅니다. 따라서 행(0), 열(1) 중 열을 기준으로 최댓값을 뽑아 예측값을 하나 만드는 것입니다. \n",
        "\n",
        "예를 들어서 배치 크기가 2이고 클래스가 3개인 outputs가 있다고 생각해봅니다.\n",
        "\n",
        "outputs = [[0.1, 0.4, 0.5], [0.2, 0.6, 0,2]] \n",
        "\n",
        "여기서의 최댓값의 위치는 2번째(0.5)와 1번째(0.6)입니다. 즉, 첫번째 이미지는 2라고 예측하는 것이고 두번째 이미지는 1이라고 예측을 하게 됩니다. 이를 torch.max를 이용하여 나타냅니다.\n",
        "\n",
        "torch.max는 최댓값과 최댓값의 위치를 산출해주는데 여기서 우리는 최댓값은 필요가 없으므로 받지 않아도 됩니다.\n",
        "\n",
        "따라서 _ (언더바)로 처리하여 해당 출력값은 저장하지 않겠다는 의미입니다. 즉, _, predicted는 최댓값의 위치만 predicted에 저장하겠다는 의미입니다.\n",
        "\n",
        "따라서 _, predicted = torch.max(outputs.data, 1)의 의미는 각 열(1)마다 최댓값의 위치를 예측값으로 사용하겠다는 의미입니다. \n",
        "\n",
        "마지막으로 .data는 예측값을 계산할 때는 역전파 계산이 필요없기 때문에 데이터만 사용한다는 의미에서 사용된 것입니다. \n",
        "\n",
        "( 그런데 지금 보니까 with torch.no_grad()를 사용했기 때문에 .data를 없애도 될 것 같습니다.)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "wzfb1eAtcoQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fifY1vaJJEgG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}